{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "17MXIcwM7kGA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrcrDOqd-Gox",
        "colab_type": "text"
      },
      "source": [
        "*AI/ML Society 2nd October 2019*\n",
        "# Introduction to Machine Learning:\n",
        "## *The MNIST handwritten digits Dataset*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gYKmk70_8iL",
        "colab_type": "text"
      },
      "source": [
        "*Author: Antoine Khoury. This data set was made available by Yann LeCun. This tutorial is based of ressouces from scikit-learn.org.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgztdFm-4waI",
        "colab_type": "text"
      },
      "source": [
        "### Multiple libraries required to import, visualize and treat the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW3N9rhBBqfh",
        "colab_type": "text"
      },
      "source": [
        "> Some libraries aren't imported yet to keep a delimitation between the different parts, but you can import everything at the beginning if prefered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSJZNBH94t7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from sklearn import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexG9TLV5AeI",
        "colab_type": "text"
      },
      "source": [
        "## 1) Import the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Vak7im5Q-q",
        "colab_type": "text"
      },
      "source": [
        "#### *Import the data and store them in 2 variables: The matrix with the image and the corresponding value*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVhm-POJCD1o",
        "colab_type": "text"
      },
      "source": [
        "> Here the package \"datasets\" provides us the MNIST dataset. The \"images\" attribute of the package is the matrices of 8x8 dimession storing the images while \"target\" is the corresponding numbers for each matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEJHvUIE5LOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "Input_images = datasets.load_digits()\n",
        "X = Input_images.images\n",
        "y = Input_images.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubX1KDwL5jPO",
        "colab_type": "text"
      },
      "source": [
        "#### *Visualize how the data is stored*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arbHon885mry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = 80\n",
        "print (X[i])\n",
        "print ('The corresponding value is: \\n', y[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VY2KVv55rNo",
        "colab_type": "text"
      },
      "source": [
        "#### *Show what this corresponds to*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qch9P0iSDfe7",
        "colab_type": "text"
      },
      "source": [
        "> To store an image on a grey scale, all you have to do is associate a value to each of it's pixels.\n",
        "Here we use matplotlib to represent this matrix of numbers as the image it corresponds to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J160qZ8m5w7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(X[i], cmap=plt.cm.gray_r)\n",
        "print(\"\\n\",y[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIa1Cone6VaH",
        "colab_type": "text"
      },
      "source": [
        "## 2) Process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cijygQE6lj4",
        "colab_type": "text"
      },
      "source": [
        "#### *We need to flatten the matrix: Instead of having the image in a 8x8 format, we change it to an array of size 64*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv3hGhd7D8Dd",
        "colab_type": "text"
      },
      "source": [
        "> This is required because our model will only take arrays as inputs ie. not matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtz2tIAQ623I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_samples = len(X)\n",
        "X_reshaped = np.reshape(X,(number_of_samples,64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BPkGbDN68N1",
        "colab_type": "text"
      },
      "source": [
        "#### *Split between train and test*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWojuNoWEJcI",
        "colab_type": "text"
      },
      "source": [
        "> When training a model, we want to be able to test it's accuracy on \"never seen\" data. To do so, we need to keep away part of our data than try it whenever we test the machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LT6Xbua7BqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_reshaped, y, test_size = 0.7, random_state = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2UL0XFC7GfT",
        "colab_type": "text"
      },
      "source": [
        "## 3) Training our model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBa9TqubExOi",
        "colab_type": "text"
      },
      "source": [
        "> Here we will use a simple Support Vector Machine for classification to execute the required task. In later workshops we will discuss other modules and compare them.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzZbJClt7MkO",
        "colab_type": "text"
      },
      "source": [
        "#### *Import the model chosen: Support Vector Machine*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYlZnDQK7Z6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABA_pVFB7cYt",
        "colab_type": "text"
      },
      "source": [
        "#### *Create the model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srD_13377hTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVM = svm.SVC(gamma=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17MXIcwM7kGA",
        "colab_type": "text"
      },
      "source": [
        "#### *Train the model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oepwxDQB7nWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SVM.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74-Zuox7sM7",
        "colab_type": "text"
      },
      "source": [
        "#### *Predict values with the already trained model*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyLqRyMLFa7J",
        "colab_type": "text"
      },
      "source": [
        "> For the test data, let's now see what the machine will predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6YWPVqI77VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted = SVM.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bii1_kAj7_vK",
        "colab_type": "text"
      },
      "source": [
        "#### *Show what these predictions correspond to*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INh0Hl8vFnlN",
        "colab_type": "text"
      },
      "source": [
        "> Let's visualize what predictions were made for our images. However we have already flatten our input data, so we need to put it back to it's orignial form ie. 8x8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi7wmakQI3RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwVtZoL37ytQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_reshaped = np.reshape(x_test,(len(x_test),8,8))\n",
        "i = 20\n",
        "plt.imshow(x_test_reshaped[i], cmap=plt.cm.gray_r)\n",
        "print(\"The algorithm predicted: \\n\",y_predicted[i])\n",
        "print(\"The true value is: \\n\",y_test[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v-6nwS78J7E",
        "colab_type": "text"
      },
      "source": [
        "## 4) Get a sense of how well our algorithm did"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzfkkUB1F9my",
        "colab_type": "text"
      },
      "source": [
        "> This section is vital to evaluate our model and see if he is viable. It will compare the predicted values with the true value. The two metrics shown here will be discussed later on in the semester."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmQ7BxQq8QXW",
        "colab_type": "text"
      },
      "source": [
        "#### *Import Mean square error and confusion matrix to try to get a taste of how good the algorithm did*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naTOt3-M8UsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KqEkinR9SFp",
        "colab_type": "text"
      },
      "source": [
        "#### *Display these metrics*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTa_ylxB9UZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "percentage_accuracy = accuracy_score(y_predicted,y_test)*100\n",
        "print (\"Percentage accuracy of the Support Vector Machine is: %s,\" %percentage_accuracy )\n",
        "\n",
        "mean_squared_error = mean_squared_error(y_test, y_predicted)\n",
        "print (\"Mean squared error of the Support Vector Machine is: %s,\"%mean_squared_error)\n",
        "\n",
        "confusion_matrix = confusion_matrix(y_test, y_predicted)\n",
        "print (\"The Confusion matrix is: \\n\",confusion_matrix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT17TdrOHPZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Further ressources\n",
        "# import a few classifiers, explore from http://scikit-learn.org/stable/supervised_learning.html to compare classification algo performance.\n",
        "# logistic regression and Bernoulli naive Bayes\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afGAL0qcuEOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}